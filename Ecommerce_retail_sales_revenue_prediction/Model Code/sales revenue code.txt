import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocessing & features
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler

# Model selection & split
from sklearn.model_selection import train_test_split

# Models (we will use exactly 3 simple models later)
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor

# Evaluation
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

df = pd.read_csv('/content/drive/MyDrive/Machine learning project/ecommerce_sales.csv')

print("Shape:", df.shape)
print("\nColumns:", df.columns.tolist())
print("\nHead:")
print(df.head().to_string())
print("\nInfo:")
print(df.info())
print("\nDescribe (numeric):")
print(df.describe().T)

# STEP 2 ‚Äî Data Analysis / Data Reading

print("\nüîç Missing Values:")
print(df.isnull().sum())

print("\nüìä Basic Statistics (Numeric Columns):")
print(df.describe().T)

print("\nüß± Data Types:")
print(df.dtypes)

# Identify numeric and categorical columns
numeric_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

print("\nüî¢ Numeric Columns:", numeric_cols)
print("\nüî§ Categorical Columns:", categorical_cols)

# Show top values for first 5 categorical columns
print("\nüìå Sample Value Counts of Categorical Columns:")
for col in categorical_cols[:5]:
    print(f"\nColumn: {col}")
    print(df[col].value_counts().head(10))

# STEP 3 ‚Äî Handling Missing Values

print("Missing values per column:")
print(df.isnull().sum())

print("\nConclusion: No missing values found, so no filling or dropping is required.")

# STEP 4 ‚Äî Data Processing / Cleaning

# 4.1 Convert Transaction_Date to datetime
df['Transaction_Date'] = pd.to_datetime(df['Transaction_Date'], format='%d-%m-%Y')

# 4.2 Remove impossible values
df = df[df['Conversion_Rate'] <= 1]
df = df[df['Revenue'] >= 0]
df = df[df['Units_Sold'] >= 0]
df = df[df['Clicks'] >= 0]
df = df[df['Impressions'] >= 0]

# Optional: Remove cases where clicks are zero but impressions > 0
df = df[~((df['Clicks'] == 0) & (df['Impressions'] > 0))]

# 4.3 Remove duplicates
duplicates = df.duplicated().sum()
df = df.drop_duplicates()

# 4.4 Check final datatypes
print("Shape after cleaning:", df.shape)
print("\nDuplicates removed:", duplicates)
print("\nFinal Data Types:")
print(df.dtypes)

df['Transaction_Date'] = pd.to_datetime(df['Transaction_Date'], format='%d-%m-%Y', errors='coerce')
daily = df.set_index('Transaction_Date').resample('D')['Revenue'].mean()

daily_clip = daily.clip(upper=daily.quantile(0.99))
smooth = daily_clip.rolling(7, min_periods=1).mean()


# STEP 5 ‚Äî Plotting & Analysis

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")
plt.figure(figsize=(12, 8))


# ------------------------------
# (A) DISTRIBUTION PLOTS
# ------------------------------

plt.figure(figsize=(14, 10))

plt.subplot(2, 3, 1)
sns.histplot(df['Revenue'], bins=30, kde=True)
plt.title("Revenue Distribution")

plt.subplot(2, 3, 2)
sns.histplot(df['Units_Sold'], bins=30, kde=True)
plt.title("Units Sold Distribution")

plt.subplot(2, 3, 3)
sns.histplot(df['Clicks'], bins=30, kde=True)
plt.title("Clicks Distribution")

plt.subplot(2, 3, 4)
sns.histplot(df['Discount_Applied'], bins=30, kde=True)
plt.title("Discount Distribution")

plt.subplot(2, 3, 5)
sns.histplot(df['Conversion_Rate'], bins=30, kde=True)
plt.title("Conversion Rate Distribution")

plt.tight_layout()
plt.show()


# ------------------------------
# (B) BOXPLOTS
# ------------------------------

plt.figure(figsize=(12, 4))
sns.boxplot(x=df['Revenue'])
plt.title("Revenue Boxplot")
plt.show()

plt.figure(figsize=(12, 4))
sns.boxplot(x=df['Units_Sold'])
plt.title("Units Sold Boxplot")
plt.show()


# ------------------------------
# (C) SCATTER PLOTS
# ------------------------------

sample = df.sample(8000, random_state=42)

plt.figure(figsize=(8, 5))
sns.scatterplot(data=sample, x='Units_Sold', y='Revenue', alpha=0.4)
plt.title("Units Sold vs Revenue")
plt.show()

plt.figure(figsize=(8, 5))
sns.scatterplot(data=sample, x='Clicks', y='Revenue', alpha=0.4)
plt.title("Clicks vs Revenue")
plt.show()

plt.figure(figsize=(8, 5))
sns.scatterplot(data=sample, x='Impressions', y='Revenue', alpha=0.4)
plt.title("Impressions vs Revenue")
plt.show()

plt.figure(figsize=(12,4))
plt.plot(smooth.index, smooth, linewidth=2, label='7-day smoothed (99% cap)')
plt.title('Daily Average Revenue (smoothed)'); plt.xlabel('Date'); plt.ylabel('Revenue')
plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()

# ===== Step 6: Feature Engineering =====

# Revenue per Unit
df['Revenue_per_Unit'] = df['Revenue'] / df['Units_Sold']

# CTR Impact (safe version)
df['CTR_Impact'] = df['Clicks'] / (df['Impressions'] + 1)

# CPC Efficiency
df['CPC_Efficiency'] = df['Ad_Spend'] / (df['Clicks'] + 1)

# ROI (Return on Investment)
df['ROI'] = (df['Revenue'] - df['Ad_Spend']) / (df['Ad_Spend'] + 1)

# Discount Effect
df['Discount_Effect'] = df['Units_Sold'] * df['Discount_Applied']

df[['Revenue_per_Unit','CTR_Impact','CPC_Efficiency','ROI','Discount_Effect']].head()

# ===== Step 8: Data Splitting (X & y) =====
from sklearn.model_selection import train_test_split

# Choose target
target = 'Revenue'

# Prepare X (drop target) and y
X = df_encoded.drop(columns=[target]).copy()
y = df_encoded[target].copy()

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42
)

# Quick checks
print("X_train shape:", X_train.shape)
print("X_test shape: ", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape: ", y_test.shape)
print("\ny_train summary:")
print(y_train.describe())

# ===== Step 9: Standardization =====
from sklearn.preprocessing import StandardScaler
import joblib
import numpy as np

scaler = StandardScaler()

# numeric columns in X_train
num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()

# make copies and scale numeric cols
X_train_scaled = X_train.copy()
X_test_scaled  = X_test.copy()

X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test_scaled[num_cols]  = scaler.transform(X_test[num_cols])

# quick check
print("Scaled numeric cols mean ~0 and std ~1 (train):")
print(np.round(X_train_scaled[num_cols].describe().T[['mean','std']], 3))

# save scaler for later use (optional)
joblib.dump(scaler, "standard_scaler.pkl")
print("Saved -> ./standard_scaler.pkl")

# ===== Step 10: Model Building (Fixed version) =====
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pandas as pd, numpy as np, joblib
import time
import matplotlib.pyplot as plt

models = {
    'Linear': LinearRegression(),
    'DecisionTree': DecisionTreeRegressor(random_state=42),
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42)
}

results = []
trained = {}

for name, model in models.items():
    t0 = time.time()
    model.fit(X_train_scaled, y_train)
    t = time.time() - t0

    y_pred = model.predict(X_test_scaled)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)                    # <‚Äî FIXED: manual RMSE
    r2 = r2_score(y_test, y_pred)

    results.append({'Model': name, 'MAE': mae, 'RMSE': rmse, 'R2': r2, 'TrainTime_s': round(t,2)})
    trained[name] = model

res_df = pd.DataFrame(results).sort_values('RMSE')
print(res_df.round(4))

# RMSE comparison plot
plt.figure(figsize=(7,4))
plt.bar(res_df['Model'], res_df['RMSE'])
plt.title("Model RMSE Comparison")
plt.ylabel("RMSE")
plt.tight_layout()
plt.show()

# Save best model
best_name = res_df.iloc[0]['Model']
best_model = trained[best_name]
joblib.dump(best_model, f"{best_name}_model.pkl")

print(f"Best model: {best_name} saved as {best_name}_model.pkl")

# STEP 11A ‚Äî Evaluation & plots (use saved best model)
import joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score

sns.set(style="whitegrid")
model = joblib.load("RandomForest_model.pkl")   # already saved

y_pred = model.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred) ** 0.5
r2  = r2_score(y_test, y_pred)
ev  = explained_variance_score(y_test, y_pred)

print(f"MAE: {mae:.4f}  RMSE: {rmse:.4f}  R2: {r2:.4f}  EV: {ev:.4f}")

# 1) Actual vs Predicted scatter (nice for slides)
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, s=10, alpha=0.4)
mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
plt.plot([mn,mx],[mn,mx],'r--', linewidth=1)
plt.xlabel("Actual Revenue")
plt.ylabel("Predicted Revenue")
plt.title("Actual vs Predicted")
plt.tight_layout()
plt.show()

# 2) Residuals distribution
residuals = y_test - y_pred
plt.figure(figsize=(6,4))
sns.histplot(residuals, bins=40, kde=True)
plt.title("Residuals Distribution")
plt.xlabel("Actual - Predicted")
plt.tight_layout()
plt.show()

# 3) Feature importance (top 15)
fi = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(15)
plt.figure(figsize=(7,5))
sns.barplot(x=fi.values, y=fi.index)
plt.title("Top 15 Feature Importances (RandomForest)")
plt.tight_layout()
plt.show()

